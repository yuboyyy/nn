#!/usr/bin/env python3
import sys
import os
import numpy as np
import cv2
import matplotlib.pyplot as plt
from tqdm import tqdm
from tensorflow.keras.models import load_model

from common.transformations.camera import transform_img, eon_intrinsics
from common.transformations.model import medmodel_intrinsics
from common.tools.lib.parser import parser

def frames_to_tensor(frames):
    if len(frames) == 0:
        return np.array([])
    H = (frames.shape[1] * 2) // 3
    W = frames.shape[2]
    tensor = np.zeros((frames.shape[0], 6, H//2, W//2), dtype=np.float32)
    tensor[:, 0] = frames[:, 0:H:2, 0::2]
    tensor[:, 1] = frames[:, 1:H:2, 0::2]
    tensor[:, 2] = frames[:, 0:H:2, 1::2]
    tensor[:, 3] = frames[:, 1:H:2, 1::2]
    tensor[:, 4] = frames[:, H:H+H//4].reshape((-1, H//2, W//2))
    tensor[:, 5] = frames[:, H+H//4:H+H//2].reshape((-1, H//2, W//2))
    return tensor / 128.0 - 1.0

def preprocess_frames(imgs):
    if not imgs:
        return np.array([])
    processed = np.zeros((len(imgs), 384, 512), dtype=np.uint8)
    for i, img in enumerate(imgs):
        try:
            processed[i] = transform_img(img, from_intr=eon_intrinsics, to_intr=medmodel_intrinsics, yuv=True, output_size=(512, 256))
        except:
            processed[i] = np.zeros((384, 512), dtype=np.uint8)
    return frames_to_tensor(processed)

def read_video_with_opencv(video_path, max_frames=10):  # å…³é”®ï¼šå¸§æ•°ä»20å‡åˆ°10ï¼Œè¿›ä¸€æ­¥é™ä½å‹åŠ›
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        raise Exception(f"æ— æ³•æ‰“å¼€è§†é¢‘ï¼š{video_path}ï¼Œè¯·å®‰è£…FFmpegï¼ˆsudo apt install ffmpegï¼‰")
    imgs = []
    raw_frames = []
    for i in range(max_frames):
        ret, frame = cap.read()
        if not ret:
            break
        raw_frames.append(frame)
        yuv = cv2.cvtColor(frame, cv2.COLOR_BGR2YUV_I420)
        yuv_resized = cv2.resize(yuv, (512, 384), interpolation=cv2.INTER_AREA)
        imgs.append(yuv_resized)
    cap.release()
    return imgs, raw_frames

def main():
    if len(sys.argv) != 2:
        print("ç”¨æ³•: python main.py <è§†é¢‘æ–‡ä»¶è·¯å¾„>")
        sys.exit(1)
    video_path = sys.argv[1]
    if not os.path.exists(video_path):
        print(f"é”™è¯¯ï¼šè§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨ - {video_path}")
        sys.exit(1)

    model_path = "models/supercombo.h5"
    if not os.path.exists(model_path):
        print(f"é”™è¯¯ï¼šæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ - {model_path}")
        sys.exit(1)

    # åŠ è½½æ¨¡å‹
    try:
        print(f"åŠ è½½æ¨¡å‹ï¼š{model_path}")
        supercombo = load_model(model_path, compile=False)
    except Exception as e:
        print(f"æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{str(e)}")
        sys.exit(1)

    # è¯»å–è§†é¢‘ï¼ˆä»…10å¸§ï¼‰
    try:
        print(f"è¯»å–è§†é¢‘ï¼š{video_path}ï¼ˆä»…10å¸§ï¼Œè½»é‡åŒ–æ¨¡å¼ï¼‰")
        imgs, raw_frames = read_video_with_opencv(video_path)
        if not imgs:
            print("é”™è¯¯ï¼šæœªè¯»å–åˆ°å¸§")
            sys.exit(1)
    except Exception as e:
        print(f"è§†é¢‘è¯»å–å¤±è´¥ï¼š{str(e)}")
        sys.exit(1)

    # é¢„å¤„ç†å¸§
    print("é¢„å¤„ç†å¸§æ•°æ®...")
    frame_tensors = preprocess_frames(imgs)
    if frame_tensors.size == 0:
        print("é”™è¯¯ï¼šé¢„å¤„ç†æ— æœ‰æ•ˆæ•°æ®")
        sys.exit(1)

    # åˆå§‹åŒ–æ¨¡å‹çŠ¶æ€
    state = np.zeros((1, 512))
    desire = np.zeros((1, 8))

    # -------------------------- è½»é‡åŒ–å¯è§†åŒ–ï¼ˆä»…1ä¸ªçª—å£ï¼Œåªç”»è½¦é“çº¿ï¼‰ --------------------------
    plt.ion()  # å¼€å¯äº¤äº’æ¨¡å¼ï¼ˆç®€åŒ–ç‰ˆï¼‰
    fig, ax = plt.subplots(figsize=(8, 6))  # å•ä¸ªçª—å£ï¼Œé¿å…å­å›¾æ¸²æŸ“å‹åŠ›
    ax.set_title("è½¦é“çº¿é¢„æµ‹ï¼ˆè“=å·¦è½¦é“ï¼Œçº¢=å³è½¦é“ï¼Œç»¿=è·¯å¾„ï¼‰")
    ax.set_ylim(0, 191)  # å›ºå®šYè½´ï¼Œå‡å°‘é‡ç»˜è®¡ç®—
    ax.invert_xaxis()     # åŒ¹é…é©¾é©¶è§†è§’
    ax.grid(alpha=0.3)    # ç®€å•ç½‘æ ¼ï¼Œä¸å èµ„æº

    # åˆå§‹åŒ–ä¸‰æ¡çº¿ï¼ˆæå‰åˆ›å»ºï¼Œé¿å…æ¯æ¬¡é‡ç»˜æ–°å»ºï¼‰
    lll_line, = ax.plot([], [], "b-", linewidth=3, label="å·¦è½¦é“çº¿")
    rll_line, = ax.plot([], [], "r-", linewidth=3, label="å³è½¦é“çº¿")
    path_line, = ax.plot([], [], "g-", linewidth=2, label="é¢„æµ‹è·¯å¾„")
    ax.legend()
    # -------------------------------------------------------------------

    # é€å¸§æ¨ç†+è½»é‡åŒ–å¯è§†åŒ–
    print(f"\nå¼€å§‹æ¨ç†+å¯è§†åŒ–ï¼ˆå…±{len(frame_tensors)-1}å¸§ï¼ŒæŒ‰Qé”®é€€å‡ºï¼‰...")
    for i in range(len(frame_tensors) - 1):
        try:
            # æ¨¡å‹æ¨ç†
            inputs = [np.vstack(frame_tensors[i:i+2])[None], desire, state]
            outs = supercombo.predict(inputs, verbose=0)
            parsed = parser(outs)
            state = outs[-1]

            # -------------------------- ä»…æ›´æ–°çº¿çš„æ•°æ®ï¼Œä¸é‡ç»˜æ•´ä¸ªçª—å£ --------------------------
            lll_line.set_data(parsed["lll"][0], range(192))  # åªæ›´æ–°å·¦è½¦é“çº¿æ•°æ®
            rll_line.set_data(parsed["rll"][0], range(192))  # åªæ›´æ–°å³è½¦é“çº¿æ•°æ®
            path_line.set_data(parsed["path"][0], range(192))# åªæ›´æ–°è·¯å¾„æ•°æ®
            fig.canvas.draw()  # è½»é‡é‡ç»˜ï¼ˆåªæ›´æ”¹é€ å˜çš„éƒ¨åˆ†ï¼‰
            fig.canvas.flush_events()  # å¼ºåˆ¶åˆ·æ–°çª—å£ï¼Œé¿å…å¡ä½
            # -------------------------------------------------------------------

            # æ˜¾ç¤ºåŸå§‹å¸§ï¼ˆç®€åŒ–ç‰ˆï¼Œç”¨Matplotlibæ˜¾ç¤ºï¼Œé¿å…OpenCVé¢å¤–çª—å£ï¼‰
            if i < len(raw_frames):
                # æ–°å»ºä¸€ä¸ªå°çª—å£æ˜¾ç¤ºåŸå§‹å¸§ï¼Œå‡å°‘æ¸²æŸ“å‹åŠ›
                cv2.imshow("åŸå§‹å¸§", cv2.resize(raw_frames[i], (480, 270)))  # ç¼©å°å°ºå¯¸
                if cv2.waitKey(100) & 0xFF == ord('q'):  # å»¶é•¿ç­‰å¾…æ—¶é—´ï¼Œç»™CPUå–˜æ¯
                    print("ç”¨æˆ·æŒ‰Qé”®é€€å‡º")
                    break

            print(f"âœ… å¸§ {i+1}/{len(frame_tensors)-1} å®Œæˆ")

        except Exception as e:
            print(f"âš ï¸  å¸§ {i+1} å¤±è´¥ï¼š{str(e)}")
            continue

    # é‡Šæ”¾èµ„æºï¼ˆç®€åŒ–ç‰ˆï¼‰
    print("\nğŸ‰ å¤„ç†å®Œæˆï¼")
    plt.ioff()
    plt.close()
    cv2.destroyAllWindows()

if __name__ == "__main__":
    main()