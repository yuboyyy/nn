import os
import shutil
import random
import numpy as np
from PIL import Image
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt

def split_dataset(dataset_path, train_dir, test_dir, split_ratio=0.8):
    """
    å°†åŸå§‹æ•°æ®é›†åˆ†å‰²ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†
    """
    print("=" * 50)
    print("å¼€å§‹æ•°æ®é›†åˆ†å‰²...")
    print(f"åŸå§‹æ•°æ®é›†è·¯å¾„: {dataset_path}")
    print(f"è®­ç»ƒé›†è·¯å¾„: {train_dir}")
    print(f"æµ‹è¯•é›†è·¯å¾„: {test_dir}")
    print(f"åˆ†å‰²æ¯”ä¾‹: {split_ratio * 100}% è®­ç»ƒ, {(1-split_ratio) * 100}% æµ‹è¯•")
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(train_dir, exist_ok=True)
    os.makedirs(test_dir, exist_ok=True)
    
    # æ£€æŸ¥åŸå§‹æ•°æ®é›†æ˜¯å¦å­˜åœ¨
    if not os.path.exists(dataset_path):
        print(f"âŒ é”™è¯¯: åŸå§‹æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {dataset_path}")
        return False
    
    # è·å–æ‰€æœ‰ç±»åˆ«
    classes = [d for d in os.listdir(dataset_path) 
               if os.path.isdir(os.path.join(dataset_path, d))]
    
    if not classes:
        print(f"âŒ é”™è¯¯: åœ¨ {dataset_path} ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç±»åˆ«æ–‡ä»¶å¤¹!")
        return False
    
    print(f"æ‰¾åˆ° {len(classes)} ä¸ªç±»åˆ«: {classes}")
    
    total_images = 0
    # éå†æ¯ä¸ªç±»åˆ«æ–‡ä»¶å¤¹
    for class_name in classes:
        class_path = os.path.join(dataset_path, class_name)
        
        # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
        images = [img for img in os.listdir(class_path) 
                 if img.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.tif'))]
        
        if not images:
            print(f"âš ï¸  è­¦å‘Š: ç±»åˆ« '{class_name}' ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
            continue
            
        random.shuffle(images)  # éšæœºæ‰“ä¹±
        
        split_index = int(len(images) * split_ratio)
        train_images = images[:split_index]
        test_images = images[split_index:]
        
        # åˆ›å»ºè®­ç»ƒå’Œæµ‹è¯•çš„ç±»åˆ«ç›®å½•
        train_class_dir = os.path.join(train_dir, class_name)
        test_class_dir = os.path.join(test_dir, class_name)
        
        os.makedirs(train_class_dir, exist_ok=True)
        os.makedirs(test_class_dir, exist_ok=True)
        
        # å¤åˆ¶è®­ç»ƒå›¾ç‰‡
        for img in train_images:
            src_path = os.path.join(class_path, img)
            dst_path = os.path.join(train_class_dir, img)
            shutil.copy2(src_path, dst_path)
        
        # å¤åˆ¶æµ‹è¯•å›¾ç‰‡
        for img in test_images:
            src_path = os.path.join(class_path, img)
            dst_path = os.path.join(test_class_dir, img)
            shutil.copy2(src_path, dst_path)
        
        print(f"âœ… ç±»åˆ« '{class_name}': {len(train_images)} è®­ç»ƒ + {len(test_images)} æµ‹è¯• = {len(images)} æ€»å›¾ç‰‡")
        total_images += len(images)
    
    print(f"ğŸ‰ æ•°æ®é›†åˆ†å‰²å®Œæˆ! æ€»å…±å¤„ç† {total_images} å¼ å›¾ç‰‡")
    print("=" * 50)
    return True

# è®¾ç½®è®¾å¤‡
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ä½¿ç”¨è®¾å¤‡: {device}")

# è·¯å¾„è®¾ç½®
base_dir = "./data"
dataset_dir = os.path.join(base_dir, "dataset")  # åŸå§‹æ•°æ®é›†è·¯å¾„
train_dir = os.path.join(base_dir, "train")
test_dir = os.path.join(base_dir, "test")

# æ£€æŸ¥å¹¶åˆ†å‰²æ•°æ®é›†
if not os.path.exists(train_dir) or not os.listdir(train_dir):
    print("è®­ç»ƒé›†ä¸å­˜åœ¨æˆ–ä¸ºç©ºï¼Œå¼€å§‹è‡ªåŠ¨åˆ†å‰²æ•°æ®é›†...")
    success = split_dataset(dataset_dir, train_dir, test_dir, split_ratio=0.8)
    if not success:
        print("âŒ æ•°æ®é›†åˆ†å‰²å¤±è´¥ï¼Œè¯·æ£€æŸ¥åŸå§‹æ•°æ®é›†è·¯å¾„")
        exit(1)
else:
    print("âœ… è®­ç»ƒé›†å·²å­˜åœ¨ï¼Œè·³è¿‡æ•°æ®é›†åˆ†å‰²æ­¥éª¤")

# æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
print("=" * 50)
print("è·¯å¾„æ£€æŸ¥:")
print(f"åŸºç¡€ç›®å½•: {base_dir}, å­˜åœ¨: {os.path.exists(base_dir)}")
print(f"åŸå§‹æ•°æ®é›†: {dataset_dir}, å­˜åœ¨: {os.path.exists(dataset_dir)}")
print(f"è®­ç»ƒç›®å½•: {train_dir}, å­˜åœ¨: {os.path.exists(train_dir)}")
print(f"æµ‹è¯•ç›®å½•: {test_dir}, å­˜åœ¨: {os.path.exists(test_dir)}")
print("=" * 50)

# å‚æ•°é…ç½®
img_size = (128, 128)
batch_size = 32
epochs = 70
num_classes = 0

# è‡ªå®šä¹‰æ•°æ®é›†ç±»
class ImageDataset(Dataset):
    def __init__(self, data_dir, transform=None):
        self.data_dir = data_dir
        self.transform = transform
        self.images = []
        self.labels = []
        self.class_to_idx = {}
        
        print(f"\næ­£åœ¨åˆå§‹åŒ–æ•°æ®é›†: {data_dir}")
        
        if not os.path.exists(data_dir):
            print(f"é”™è¯¯: æ•°æ®ç›®å½• {data_dir} ä¸å­˜åœ¨!")
            return
        
        classes = sorted([d for d in os.listdir(data_dir) 
                         if os.path.isdir(os.path.join(data_dir, d))])
        
        if not classes:
            print(f"è­¦å‘Š: åœ¨ {data_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç±»åˆ«æ–‡ä»¶å¤¹!")
            return
        
        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}
        print(f"æ‰¾åˆ°ç±»åˆ«: {self.class_to_idx}")
        
        total_images = 0
        for class_name in classes:
            class_dir = os.path.join(data_dir, class_name)
            class_images = []
            
            supported_formats = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif')
            for img_name in os.listdir(class_dir):
                if img_name.lower().endswith(supported_formats):
                    img_path = os.path.join(class_dir, img_name)
                    class_images.append(img_path)
            
            print(f"ç±»åˆ« '{class_name}': æ‰¾åˆ° {len(class_images)} å¼ å›¾ç‰‡")
            
            self.images.extend(class_images)
            self.labels.extend([self.class_to_idx[class_name]] * len(class_images))
            total_images += len(class_images)
        
        print(f"æ•°æ®é›†æ€»è®¡: {total_images} å¼ å›¾ç‰‡")
    
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        img_path = self.images[idx]
        label = self.labels[idx]
        
        try:
            image = Image.open(img_path).convert('RGB')
            if self.transform:
                image = self.transform(image)
            return image, label
        except Exception as e:
            print(f"åŠ è½½å›¾åƒå¤±è´¥: {img_path}, é”™è¯¯: {e}")
            image = Image.new('RGB', (128, 128), color='black')
            if self.transform:
                image = self.transform(image)
            return image, label

# æ•°æ®é¢„å¤„ç†
train_transform = transforms.Compose([
    transforms.Resize(img_size),
    transforms.RandomRotation(30),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), shear=0.2),
    transforms.ColorJitter(brightness=0.2, contrast=0.2),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

test_transform = transforms.Compose([
    transforms.Resize(img_size),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# åˆ›å»ºæ•°æ®é›†å’Œæ•°æ®åŠ è½½å™¨
print("\n" + "=" * 50)
print("åˆ›å»ºæ•°æ®é›†...")
train_dataset = ImageDataset(train_dir, transform=train_transform)
test_dataset = ImageDataset(test_dir, transform=test_transform)

if len(train_dataset) == 0:
    print("\né”™è¯¯: è®­ç»ƒé›†ä¸ºç©º!")
    print("è¯·æ£€æŸ¥æ•°æ®é›†åˆ†å‰²æ˜¯å¦æ­£ç¡®å®Œæˆ")
    exit(1)

num_classes = len(train_dataset.class_to_idx)
print(f"\næ£€æµ‹åˆ° {num_classes} ä¸ªç±»åˆ«: {train_dataset.class_to_idx}")
print(f"è®­ç»ƒé›†æ ·æœ¬æ•°: {len(train_dataset)}")
print(f"æµ‹è¯•é›†æ ·æœ¬æ•°: {len(test_dataset)}")

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

# æ„å»ºæ¨¡å‹
class ImageClassifier(nn.Module):
    def __init__(self, num_classes):
        super(ImageClassifier, self).__init__()
        
        # ä½¿ç”¨æ–°çš„weightså‚æ•°ï¼ˆå…¼å®¹æ–°ç‰ˆæœ¬torchvisionï¼‰
        try:
            # æ–°ç‰ˆæœ¬ç”¨æ³•ï¼ˆtorchvision >= 0.13ï¼‰
            self.backbone = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
        except TypeError:
            # æ—§ç‰ˆæœ¬å…¼å®¹ï¼ˆtorchvision < 0.13ï¼‰
            self.backbone = models.resnet18(pretrained=True)
        
        # å†»ç»“é¢„è®­ç»ƒå±‚çš„å‚æ•°
        for param in self.backbone.parameters():
            param.requires_grad = False
        
        # æ›¿æ¢æœ€åçš„å…¨è¿æ¥å±‚
        in_features = self.backbone.fc.in_features
        self.backbone.fc = nn.Sequential(
            nn.Linear(in_features, 128),
            nn.ReLU(inplace=True),
            nn.Dropout(0.5),
            nn.Linear(128, num_classes)
        )
    
    def forward(self, x):
        return self.backbone(x)

# åˆå§‹åŒ–æ¨¡å‹
model = ImageClassifier(num_classes=num_classes).to(device)

# å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)

def train_model(model, train_loader, test_loader, epochs, patience=5):
    best_accuracy = 0.0
    patience_counter = 0
    train_losses = []
    val_accuracies = []
    
    for epoch in range(epochs):
        model.train()
        running_loss = 0.0
        
        for images, labels in train_loader:
            images, labels = images.to(device), labels.to(device)
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            running_loss += loss.item() * images.size(0)
        
        epoch_loss = running_loss / len(train_loader.dataset)
        train_losses.append(epoch_loss)
        
        model.eval()
        all_preds = []
        all_labels = []
        
        with torch.no_grad():
            for images, labels in test_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                _, preds = torch.max(outputs, 1)
                all_preds.extend(preds.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())
        
        accuracy = accuracy_score(all_labels, all_preds)
        val_accuracies.append(accuracy)
        
        print(f'Epoch [{epoch+1}/{epochs}], Loss: {epoch_loss:.4f}, Accuracy: {accuracy:.4f}')
        
        if accuracy > best_accuracy:
            best_accuracy = accuracy
            patience_counter = 0
            torch.save(model.state_dict(), os.path.join(base_dir, "best_model.pth"))
            print(f"ä¿å­˜æœ€ä½³æ¨¡å‹ï¼Œå‡†ç¡®ç‡: {accuracy:.4f}")
        else:
            patience_counter += 1
        
        if patience_counter >= patience:
            print(f"æ—©åœï¼šéªŒè¯å‡†ç¡®ç‡ {patience} è½®æœªæå‡")
            break
        
        scheduler.step()
    
    return train_losses, val_accuracies

# è®­ç»ƒæ¨¡å‹
print("\n" + "=" * 50)
print("å¼€å§‹è®­ç»ƒæ¨¡å‹...")
train_losses, val_accuracies = train_model(model, train_loader, test_loader, epochs)

# ä¿å­˜æœ€ç»ˆæ¨¡å‹
torch.save(model.state_dict(), os.path.join(base_dir, "final_model.pth"))
print("âœ… æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜")

# ç»˜åˆ¶è®­ç»ƒæ›²çº¿
plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(train_losses)
plt.title('Training Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')

plt.subplot(1, 2, 2)
plt.plot(val_accuracies)
plt.title('Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')

plt.tight_layout()
plt.savefig(os.path.join(base_dir, "training_plot.png"))
print("âœ… è®­ç»ƒæ›²çº¿å›¾å·²ä¿å­˜")

plt.show()

print("ğŸ‰ æ¨¡å‹è®­ç»ƒå®Œæˆï¼")

# æ˜¾ç¤ºæœ€ç»ˆç»“æœ
print("\n" + "=" * 50)
print("è®­ç»ƒæ€»ç»“:")
print(f"- è®¾å¤‡: {device}")
print(f"- ç±»åˆ«æ•°é‡: {num_classes}")
print(f"- è®­ç»ƒæ ·æœ¬: {len(train_dataset)}")
print(f"- æµ‹è¯•æ ·æœ¬: {len(test_dataset)}")
print(f"- æœ€ä½³æ¨¡å‹: {os.path.join(base_dir, 'best_model.pth')}")
print(f"- æœ€ç»ˆæ¨¡å‹: {os.path.join(base_dir, 'final_model.pth')}")
print(f"- è®­ç»ƒæ›²çº¿: {os.path.join(base_dir, 'training_plot.png')}")

print("=" * 50)
